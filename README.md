<h1> 1. RAG System with LlamaIndex</h1>

<p>This workflow demonstrates how to create a complete RAG pipeline that enhances LLM responses with factual information retrieved from a Wikipedia corpus. The system performs semantic search on Wikipedia articles and generates accurate, context-aware answers.</p>

<h2>Key Features</h2>

<ul>
  <li>Uses Wikipedia dataset from Hugging Face</li>
  <li>Implements vector search with OpenAI embeddings</li>
  <li>Generates natural language responses with GPT-4</li>
  <li>Simple architecture with minimal dependencies</li>
</ul>

<h2>Implementation Steps</h2>

<img src="https://raw.githubusercontent.com/AnkitaMungalpara/Production-Ready-RAG-with-LlamaIndex/main/rag_architecture.png" alt="RAG System Architecture" width="100%">


<h2>Notebook</h2>

<p>You can view and follow complete worflow from notebook:</p>
<a href="https://github.com/AnkitaMungalpara/Production-Ready-RAG-with-LlamaIndex/blob/main/Build_Your_First_RAG_System_with_LlamaIndex.ipynb" target="_blank">
  Build_Your_First_RAG_System_with_LlamaIndex.ipynb
</a>

<h2>Sample Queries</h2>

<ul>
  <li>"Can an infinite extension be algebraic? Give an example."</li>
  <li>"What is considered Berg's most widely known and beloved composition?"</li>
  <li>"What distinguishes atomic physics from nuclear physics?"</li>
</ul>
